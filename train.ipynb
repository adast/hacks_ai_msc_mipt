{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Others\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Make computations repeatable\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Compute on gpu if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def extract_region(img, center, size, angle):\n",
    "    # Extract region from image around the center\n",
    "    radius = np.ceil(np.sqrt(size** 2 * 2) / 2).astype(int)\n",
    "    assert min(center) >= radius, 'center is too close to the border'\n",
    "    cx, cy = center\n",
    "    roi = img[cy-radius:cy+radius, cx-radius:cx+radius]\n",
    "\n",
    "    # Rotate this region\n",
    "    h, w = roi.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "    roi = cv2.warpAffine(roi, M, (w, h))\n",
    "\n",
    "    # Center crop roi\n",
    "    start_y = (h - size) // 2\n",
    "    start_x = (w - size) // 2\n",
    "    roi = roi[start_y:start_y+size, start_x:start_x+size]\n",
    "\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_map = cv2.imread('original.tiff')\n",
    "sat_map = cv2.cvtColor(sat_map, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SATDatasetFirst(Dataset):\n",
    "    def __init__(self):\n",
    "        self.img_paths = sorted(glob.glob('train/img/*.png'))\n",
    "        self.labels = []\n",
    "        for path in sorted(glob.glob('train/json/*.json')):\n",
    "            with open(path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                left_top = np.array(data['left_top'])\n",
    "                right_bottom = np.array(data['right_bottom'])\n",
    "                center = left_top + ((right_bottom - left_top) / 2)\n",
    "                angle = data['angle']\n",
    "                self.labels.append([center, angle])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img_path = self.img_paths[index]\n",
    "        roi = cv2.imread(img_path)\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        roi = self.to_tensor(roi)\n",
    "        roi = self.normalize(roi)\n",
    "        \n",
    "        center, angle = self.labels[index]\n",
    "        center = torch.tensor(center / 10496)\n",
    "        angle = torch.tensor([np.sin(np.deg2rad(angle)), np.cos(np.deg2rad(angle))])\n",
    "        label = torch.cat([center, angle]).to(torch.float32)\n",
    "\n",
    "        return roi, label\n",
    "\n",
    "class SATDatasetSecond(Dataset):\n",
    "    def __init__(self, sat_map):\n",
    "        self.sat_map = sat_map\n",
    "        self.aug = iaa.Clouds()\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __len__(self):\n",
    "        return 3000\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        center = np.array([np.random.randint(725, 9771), np.random.randint(725, 9771)])\n",
    "        angle = np.random.randint(0, 359)\n",
    "        \n",
    "        roi = extract_region(self.sat_map, center, 1024, angle)\n",
    "        roi = self.aug(image=roi)\n",
    "        roi = self.to_tensor(roi)\n",
    "        roi = self.normalize(roi)\n",
    "\n",
    "        center = torch.tensor(center / 10496)\n",
    "        angle = torch.tensor([np.sin(np.deg2rad(angle)), np.cos(np.deg2rad(angle))])\n",
    "        label = torch.cat([center, angle]).to(torch.float32)\n",
    "\n",
    "        return roi, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1E-4\n",
    "EPOCHS = 220\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 20\n",
    "fs_ds = SATDatasetFirst()\n",
    "sc_ds = SATDatasetSecond(sat_map)\n",
    "dataset = torch.utils.data.ConcatDataset([fs_ds, sc_ds])\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdd/envs/torch_vdd/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = resnet50()\n",
    "model.fc = nn.Linear(2048, 4)\n",
    "\n",
    "checkpoint = torch.load('/home/vdd/MIPT/v2/checkpoints/epoch-175_loss_0.00019.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "last_checkpoint_epoch = -1\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = len(dataloader),\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "last_checkpoint_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, scheduler, device, writer=None, epoch_index=0):\n",
    "    # Tracking variables.\n",
    "    losses = []\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for batch_index, batch in enumerate(tqdm(dataloader, total=len(dataloader), desc=\"Training on batches\")):\n",
    "        global_batch_index = epoch_index * len(dataloader) + batch_index # Global step index\n",
    "        roi = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(roi)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip the norm of gradient to prevent gradient expolosion\n",
    "        optimizer.step() # Update weights\n",
    "        scheduler.step() # Update the learning rate.\n",
    "\n",
    "        # Write loss per batch to tensorboard\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Loss/train (per batch)', loss.item(), global_batch_index)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_DIR = '/home/vdd/MIPT/v2/tensorboard'\n",
    "CHECKPOINTS_DIR = '/home/vdd/MIPT/v2/checkpoints'\n",
    "! mkdir -p {CHECKPOINTS_DIR}\n",
    "\n",
    "# Tensorboard\n",
    "writer = SummaryWriter(log_dir=TENSORBOARD_DIR)\n",
    "\n",
    "# Loop through each epoch.\n",
    "for epoch in tqdm(range(last_checkpoint_epoch + 1, EPOCHS), desc=\"Epoch\"):\n",
    "    print(f'Running on epoch: {epoch}')\n",
    "\n",
    "    # Perform one full pass over the training and validation sets\n",
    "    train_loss = train_epoch(model, dataloader, criterion, optimizer, scheduler, device, writer, epoch)\n",
    "\n",
    "    # Populate tensorboard\n",
    "    writer.add_scalar('Loss/train (per epoch)', train_loss, epoch)\n",
    "\n",
    "    # Print loss and accuracy values to see how training evolves.\n",
    "    print(f'train_loss: {train_loss:.5f}\\n')\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict()\n",
    "        }, f\"{CHECKPOINTS_DIR}/epoch-{epoch}_loss_{train_loss:.5f}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
